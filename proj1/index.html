<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Rasterizer</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">
</head>


<body>

<h1 align="middle">CS 184: Computer Graphics and Imaging, Spring 2018</h1>
<h1 align="middle">Project 1: Rasterizer</h1>
<h2 align="middle">Noah Schwartz, Andrew Chen, CS184</h2>

<br><br>

    <div>
        <p>Webpage Link: https://github.com/cal-cs184-student/sp22-project-webpages-NoahSchwartz-Berkeley</p>

        <h2 align="middle">Overview</h2>
        
        <p>
            In this project, we implemented different methods of pixel sampling and texture sampling. These sampling methods focus on drawing pixels at the right color based on nearby pixels or a texture map, and we can see that different methods change the quality of the image by how well colors blend and how edges are shown (are they more jagged or antialiased).</P>
        <p>It was interesting to see how important extrapolating features from more pixels makes an image look better by blurring sharp, jagged edges.
        It was also amazing to see the power of supersampling, which produced the most notable visual improvements to the image for us.</p>
        <p></p><p>We hope you enjoy our code and the process of these images as much as we did!
        </p>

        <h2 align="middle">Section I: Rasterization</h2>

        <h3 align="middle">Part 1: Rasterizing single-color triangles</h3>

        <p>For this task, we drew triangles by following the example shown in lecture, where we examined the planes generated by each pair of vertices. We then took the normal vectors of those planes and checked if each sampled point was within the triangle for each of those three planes.</p>
        <p>Our code is no worse than the algorithm that checks each sample within the bounding box of the triangle because ours is exactly the algorithm that checks each sample within the bounding box of the triangle as shown in lecture.</p>
        <p>Below are pictures of our triangles:</p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/q1.png" align="middle" width="400px" />
                        <figcaption align="middle">Triangles Filled In.</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <p>Further, we created a more efficient way to rasterize the triangles by calculating the slope between every two pairs of vertices, then structuring our nested for loops so that they would be bounded within the slope of each triangle’s edge. This allows us to only render the points inside the triangle and not check every point in the bounding box. Using the steady clock class and the example code given from https://www.cplusplus.com/reference/chrono/steady_clock/, we timed rasterize_triangle() using the three line test to check every point in the bounding box, and then timed our more efficient way. As shown by the times in the image, the more efficient rasterize_triangle() is around twice as fast, which makes sense because a triangle is half the area of its bounding box.</p>
        
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/q1original0.png" align="middle" width="400px" />
                        <figcaption align="middle">Original Version</figcaption>
                    </td>
                    <td>
                        <img src="images/q1original1.png" align="middle" width="400px" />
                        <figcaption align="middle">Original Version</figcaption>
                    </td>
                    <td>
                        <img src="images/q1original2.png" align="middle" width="400px" />
                        <figcaption align="middle">Original Version</figcaption>
                    </td>
                </tr>
                <br />
                <tr>
                    <td>
                        <img src="images/q1new0.png" align="middle" width="400px" />
                        <figcaption align="middle">Improved Version</figcaption>
                    </td>
                    <td>
                        <img src="images/q1new1.png" align="middle" width="400px" />
                        <figcaption align="middle">Improved Version</figcaption>
                    </td>
                    <td>
                        <img src="images/q1new2.png" align="middle" width="400px" />
                        <figcaption align="middle">Improved Version</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <h3 align="middle">Part 2: Antialiasing triangles</h3>
        <p>We followed our regular sampling algorithm as written in task 1, but modified it by transforming our space into a larger grid (with sample_rate to define how much larger our grid should be), and in that large grid, we sampled how many of our pixels were within each triangle, taking the average depending on how many pixels blobs were within the triangle for the large grid. We then converted back to our normal size grid, but with each pixel with a modified opacity that we calculated in the large grid world by averaging. </p>
        <p>Supersampling is useful because, when checking and drawing shapes, we may get sharp edges in our drawings, where the pixels were abruptly cut short by being out of the shape bounds. Supersampling blurs out those sharp edges, making shapes look more realistic.</p>
        <p>When we supersample with 16 frames per pixel, we see that on very narrow edges, such as the triangle shown in the figure “Sample Rate: 16. Narrow Edge Triangle”, the line is almost all transparent. This is because when we supersample, the thinner the line is, the less likely it is to fit all of its points within our pixel sizes. So the majority of the shape is outside of our bounds. If we were to use a sample rate of, say 1, we’d see the thin lines either removed entirely from our render or a solid pixel encompassing it. With our sample rate of 16, as shown in the picture, the narrow lines are visible, and the transparency demonstrates how small the line is compared to our pixel dimensions. Thus our 16 sample rate is a much more realistic model for thin edges than lower sample rates. </p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/q20.png" align="middle" width="400px" />
                        <figcaption align="middle">Sample Rate = 1.</figcaption>
                    </td>
                    <td>
                        <img src="images/q21.png" align="middle" width="400px" />
                        <figcaption align="middle">Sample Rate = 4</figcaption>
                    </td>
                </tr>
                <br />
                <tr>
                    <td>
                        <img src="images/q22.png" align="middle" width="400px" />
                        <figcaption align="middle">Sample Rate = 16</figcaption>
                    </td>
                    <td>
                        <img src="images/q23.png" align="middle" width="400px" />
                        <figcaption align="middle">Sample Rate: 16. Narrow Edge Triangle</figcaption>
                    </td>
                </tr>
            </table>
        </div>
        <h3 align="middle">Part 3: Transforms</h3>

        <p>For our robot, we modified the transform matrices as shown in lecture, for translation, scaling, and rotation. We also adjusted the robot's body to fit into a dancing position, with their arms waving up and down and their legs bending inward.' </p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/robodancing.png" align="middle" width="400px" />
                        <figcaption align="middle">Robot Dancing</figcaption>
                    </td>
                </tr>
            </table>
        </div>


        <h2 align="middle">Section II: Sampling</h2>

        <h3 align="middle">Part 4: Barycentric coordinates</h3>

        <p>
            Our idea of barycentric coordinates is that each weight: alpha, beta, and gamma, is like a proportion of contribution from each of the triangle’s vertices, and each point inside the triangle is made up of a certain combination of its three vertices. The proportion of how close it is to each vertex allows us to extrapolate many factors such as position or in this project’s case, color.
            The helping image here is of the srgb spectrum. Each corner represents a color consisting of all blue, red, or green. Each of the points inside is some combination of those, and the degree of influence from each vertex comes from the barycentric coordinates. For example, barycentric coordinates of (⅓, ⅓, ⅓) would place the point around the middle of the triangle, where it takes an equal amount of red, green, and blue from each vertex.
        </p>

        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/q40.png" align="middle" width="400px" />
                        <figcaption align="middle">Barycentric Colorwheel.</figcaption>
                    </td>
                    <td>
                        <img src="images/q41.png" align="middle" width="400px" />
                        <figcaption align="middle">Helping Picture.</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <h3 align="middle">Part 5: "Pixel sampling" for texture mapping</h3>
        <p>Our idea of pixel sampling is combining the features of the pixels surrounding a pixel, either through an average or  weights, to improve on the quality of the pixel itself. It is useful for blending or extrapolation features of a pixel that would not do well in the image by itself. Nearest pixel sampling is the simplest in that it puts all the weight into the pixel closest to the coordinate you want to color. In bilinear pixel sampling, we use the closest four pixels to the coordinates (rounded up and down) to determine the features of the pixel we want to color. The distance between the four pixels determines the weight of that pixel. Being equally distant from four pixels would give a color that is an equal average of the four pixel’s colors, and being right on a pixel’s center would give all the weight to that one pixel, as the position rounded down or up would be the same pixel.</p>
        <p>For our Bilinear weighting algorithm, we took inspiration from this site: https://handwiki.org/wiki/Bilinear_filtering</p>
        
        <p>Below we show four different images comparing nearest and bilinear sampling, with their respective sampling rate. As seen from the leaves in the zoomed in portion, nearest samples the leaves as a noise of almost random shades of green, with bright pixels contrasting gravely with dim pixels. When we use bilinear however, the stark differences become a blend of smooth color transitions. Thus bilinear has a large impact on the quality of the leaves as seen in this example. Further, increasing the sample rate drastically improves both of these images, as we discussed it would from task 2. </p>
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/nearest_1.png" align="middle" width="400px" />
                        <figcaption align="middle">Nearest with Sample Rate = 1</figcaption>
                    </td>
                    <td>
                        <img src="images/bilinear_1.png" align="middle" width="400px" />
                        <figcaption align="middle">Bilinear with Sample Rate = 1</figcaption>
                        </figcaption>
                    </td>
                </tr>
                <br />
                <tr>
                    <td>
                        <img src="images/nearest_16.png" align="middle" width="400px" />
                        <figcaption align="middle">Nearest with Sample Rate = 16</figcaption>
                    </td>
                    <td>
                        <img src="images/bilinear_16.png" align="middle" width="400px" />
                        <figcaption align="middle">Bilinear with Sample Rate = 16</figcaption>
                    </td>
                </tr>
            </table>
        </div>

        <h3 align="middle">Part 6: "Level sampling" with mipmaps for texture mapping</h3>

        <p>
            Level sampling is a way to sample texture points at different resolution qualities, where ‘level’ in this sense means the resolution. Level sampling is useful when you want to render different parts of an image with different degrees of resolution (e.g. making the background more blurry, and the foreground sharp and defined). In our code, we used the formula from lecture to calculate the desired level for each pixel. From there, for Nearest, we called our task 5 sample functions, but with the rounded version of level as our mipmap parameter. For Linear, we took a weighted sum, with the distance from each of our closest integer levels with our continuous level as our weights, and the colors at each of those levels (taken from each respective sampling technique) as our values to weigh.
        </p>

        <p>
            Pixel sampling is the most optimal for memory because you don't need to keep track of different levels and you just need the default frame size. Nearest pixel sampling doesn't produce much antialiasing benefits but bilinear pixel sampling does help blend edges. Level sampling takes more memory to compute each level, but when it comes to runtime and rendering speed, level sampling is fastest since it gives more attention to important shapes and less rendering power to shapes of lesser importance. Supersampling is the slowest, as it enlarges the screen to compute, then transforms the screen back to render. But supersampling is useful to decrease and ‘fade out’ rough edges when drawing a shape.
        </p>
        
        <div align="middle">
            <table style="width=100%">
                <tr>
                    <td>
                        <img src="images/penguin0.png" align="middle" width="400px" />
                        <figcaption align="middle">L_ZERO x P_NEAREST</figcaption>
                    </td>
                    <td>
                        <img src="images/penguin1.png" align="middle" width="400px" />
                        <figcaption align="middle">L_ZERO x P_LINEAR</figcaption>
                    </td>
                </tr>
                <br />
                <tr>
                    <td>
                        <img src="images/penguin2.png" align="middle" width="400px" />
                        <figcaption align="middle">L_NEAREST x P_NEAREST</figcaption>
                    </td>
                    <td>
                        <img src="images/penguin3.png" align="middle" width="400px" />
                        <figcaption align="middle">L_NEAREST x P_LINEAR</figcaption>
                    </td>
                </tr>
            </table>
        </div>

    </div></body>
</html>
